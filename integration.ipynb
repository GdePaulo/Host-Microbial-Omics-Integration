{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import loader as load\n",
    "import processor as pr\n",
    "import config\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target=\"tumor\"\n",
    "c=\"STAD\"\n",
    "data, files_names = load.loadAll(includeStage=(target==\"stage\"), sameSamples=True, skipGenes=True)\n",
    "ge_genus, ge_genus_name = data[-1], files_names[-1]\n",
    "ge_genus = load.attachTumorStatus(ge_genus)\n",
    "\n",
    "x, y = pr.splitData(ge_genus, target=target, project=c)\n",
    "# x = x.drop(x.iloc[:, 5:5216], axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-use-datasets-and-dataloader-in-pytorch-for-custom-text-data-270eed7f7c00\n",
    "\n",
    "class OverlapDataset(Dataset):\n",
    "    \"\"\"Genus + GE dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, target, cancer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        data, files_names = load.loadAll(includeStage=(target==\"stage\"), sameSamples=True, skipGenes=True)\n",
    "        ge_genus, ge_genus_name = data[-1], files_names[-1]\n",
    "\n",
    "        if target==\"tumor\":\n",
    "            ge_genus = load.attachTumorStatus(ge_genus)\n",
    "        else:\n",
    "            ge_genus = load.attachStageStatus(ge_genus)\n",
    "\n",
    "        x, y = pr.splitData(ge_genus, target=target, project=cancer)\n",
    "        # x = x.drop(x.iloc[:, 20:5201], axis=1)\n",
    "        \n",
    "        self.modality_features = x\n",
    "        self.targets = y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.modality_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample_features = self.modality_features.iloc[idx].values\n",
    "        sample_target = self.targets.iloc[idx]\n",
    "        sample = {'features': sample_features, 'target': sample_target}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapped = OverlapDataset(\"tumor\", \"STAD\")\n",
    "# Display text and label.\n",
    "print('\\nFirst iteration of data set: ', next(iter(overlapped)), '\\n')\n",
    "# Print how many items are in the data set\n",
    "print('Length of data set: ', len(overlapped), '\\n')\n",
    "# Print entire data set\n",
    "print('Entire data set: ', list(DataLoader(overlapped))[:2], '\\n')\n",
    "\n",
    "# DataLoader is used to load the dataset\n",
    "# for training\n",
    "loader = torch.utils.data.DataLoader(dataset = overlapped,\n",
    "\t\t\t\t\t\t\t\t\tbatch_size = 16,\n",
    "\t\t\t\t\t\t\t\t\tshuffle = True)\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "print('Batched data set: ', list(loader)[:2], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://watermark.silverchair.com/1248.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAArwwggK4BgkqhkiG9w0BBwagggKpMIICpQIBADCCAp4GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMM6y26O5A0lDKtXXvAgEQgIICb8n1ZwkcrxPuUifgr-Ud12gTf4jj9M7PdE0hTB1Wa3QllSw6ZyWaQagFfvUpTjgpYrEs1z9ZG3K3rdOjyf6wfpPsmYwm31SXna_VzaNB7KpelOTufAa1n21qxSdlcEAhZBX_taNOaI8dyvL45JK8NMB9lS_u_o9s_nlYooUYSUBquE3rXTFj-B0X0nFUzXKrHOnvvH_IqN4QUlXAnq-M1Cf_4WJMHDG5WKor_7iCUOM2ggFI5QYKMbKFr7-bua_ahStqgZIWf2ha7yvAl2W0Uh7osjfX_E6dsSyQIel-iHMtlvdNyrJpewesW3hDNva6ZZT7eCQWSq1STtN2qyDaIN6owPs3Nk2JWazJOq6m-kWEUwi0xRoufdKfMPttlt97VdLUly-HPn6TLthicSi-JWcKIjyAl808KW5EgGpq-TfwPPgto9CRR3qOGj4OxoQsIvMaUySpZIztbOmjI38GRrUkLPYRDY3qj1dRdccOPEIW378tEaNQMEImqWOhpHw_YYz4jPVTNtxB8usRfjZUf572W-pRtPRPd7Ysv-SNxlsdL4CHjPDFeJqdOnm8xV99jGvn962nNH4o3uNl87hPCBENoprDcesN3yMams69_vjzaCBUEv6ry6DSr96t82wb1KKSDlY2xp-3aLKz_1NgQRNnRMzSo0lMYtvhnAJHtPWnUdrvNanhp1pPlK0JgvwZKVjMdyVBfbpnGG6KLecXTycwHB7hcdNQNx6uatOYGCuGccW6Al_Nm3guDytzmCAs9eT85rck1ZOpc5P7R1qcxlHgFOVrlQ-AIeEA7e77MtKpc4uqnubdWBn6Lot_TmqG\n",
    "# Creating a PyTorch class\n",
    "# 28*28 ==> 9 ==> 28*28\n",
    "class AE(torch.nn.Module):\n",
    "\tdef __init__(self, input_features, hidden_features):\n",
    "\t\tsuper().__init__()\n",
    "\t\t\n",
    "\t\t# Building an linear encoder with Linear\n",
    "\t\t# layer followed by Relu activation function\n",
    "\t\t# 784 ==> 9\n",
    "\t\tself.encoder = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Linear(input_features, 128),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(128, 64),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(64, 36),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(36, 18),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(18, hidden_features)\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t# Building an linear decoder with Linear\n",
    "\t\t# layer followed by Relu activation function\n",
    "\t\t# The Sigmoid activation function\n",
    "\t\t# outputs the value between 0 and 1\n",
    "\t\t# 9 ==> 784\n",
    "\t\tself.decoder = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Linear(hidden_features, 18),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(18, 36),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(36, 64),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(64, 128),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t\ttorch.nn.Linear(128, input_features),\n",
    "\t\t\ttorch.nn.Sigmoid()\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tencoded = self.encoder(x)\n",
    "\t\tdecoded = self.decoder(encoded)\n",
    "\t\treturn encoded, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model = AE(input_features=5221, hidden_features=3)\n",
    "\n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "\t\t\t\t\t\t\tlr = 1e-2,\n",
    "\t\t\t\t\t\t\tweight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "outputs = []\n",
    "losses = []\n",
    "hidden_representation = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\tfor batch_id, batched_samples in enumerate(loader):\n",
    "\t\tfeatures = batched_samples[\"features\"].float()\n",
    "\t\t\n",
    "\t\t# Output of Autoencoder\n",
    "\t\thidden, reconstructed = model(features)\n",
    "\t\t\n",
    "\t\t# Calculating the loss function\n",
    "\t\tloss = loss_function(reconstructed, features)\n",
    "\t\t\n",
    "\t\t# The gradients are set to zero,\n",
    "\t\t# the gradient is computed and stored.\n",
    "\t\t# .step() performs parameter update\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\t# Storing the losses in a list for plotting\n",
    "\t\tlosses.append(loss.detach())\n",
    "\t\toutputs.append((epochs, features, reconstructed))\n",
    "\t\thidden_representation = hidden[-1]\n",
    "\n",
    "\t\tprint(\"last hidden item: \", hidden_representation)\n",
    "\n",
    "# Defining the Plot Style\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plotting the last 100 values\n",
    "plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), config.model_state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE(input_features=5221, hidden_features=3)\n",
    "model.load_state_dict(torch.load(config.model_state_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    def extractFeatures(features):\n",
    "        print(len(features))\n",
    "        print(features.dtype)\n",
    "        features_tensor = torch.tensor(features.values).float()\n",
    "        hidden_representation, _ = model(features_tensor)\n",
    "     \n",
    "        print(hidden_representation)\n",
    "        print(len(hidden_representation))\n",
    "        return pd.Series(hidden_representation)\n",
    "\n",
    "    # OverlapDataset\n",
    "\n",
    "    x_s = x.head(2)\n",
    "    x_integrated = x_s.apply(extractFeatures, axis=1)\n",
    "    # extracted_features = model(x)\n",
    "\n",
    "print(x_integrated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bacteria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c9c23c68e4133fb152380ec4059b1f78568734598c8159b0962b671d1bd3454"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
